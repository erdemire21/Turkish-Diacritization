{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "#Handling imports of Model here. Change the model to whichever one you like. But dont forget to change the checkpoint path as well\n",
    "from LSTM_Models.MultiHeadAttentionLSTM import DiacritizationModel\n",
    "\n",
    "# Load the model from saved checkpoint\n",
    "checkpoint_path = \"Weights/MultiHeadAttention15Epochs.pth\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model = DiacritizationModel(len(checkpoint['vocab']) + 1, checkpoint['embedding_dim'])  # Assuming model class is DiacritizationModel\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define functions for tokenization and sequence preparation\n",
    "def char_tokenizer(text):\n",
    "    return list(text)\n",
    "\n",
    "def prepare_sequence(seq, vocab, device):\n",
    "    \"\"\" Convert a sequence of characters into a tensor of numerical indices. \"\"\"\n",
    "    tokens = char_tokenizer(seq)  # Tokenize the sequence into characters\n",
    "    indices = [vocab[token] for token in tokens]  # Convert tokens to indices\n",
    "    return torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension and send to device\n",
    "\n",
    "def decode_predictions(indices, vocab):\n",
    "    \"\"\" Convert a sequence of indices back to characters. \"\"\"\n",
    "    indices = indices.cpu().numpy()  # Move to CPU and convert to numpy array\n",
    "    reverse_vocab = {index: char for char, index in vocab.get_stoi().items()}\n",
    "    return ''.join([reverse_vocab[idx] for idx in indices])\n",
    "\n",
    "turkish_lowercase = \"abcçdefgğhıijklmnoöprsştuüvyz\"\n",
    "turkish_uppercase = \"ABCÇDEFGĞHIİJKLMNOÖPRSŞTUÜVYZ\"\n",
    "special_chars = \"°/.,!?;:-'0123456789()\"\n",
    "\n",
    "turkish_dict = dict(zip(turkish_lowercase, turkish_uppercase))\n",
    "\n",
    "def find_special_chars_indices(sequence):\n",
    "    return [(i,char) for i, char in enumerate(sequence) if char in special_chars]\n",
    "\n",
    "def find_uppercase_indices(sequence):\n",
    "    return [i for i, char in enumerate(sequence) if char in turkish_uppercase]\n",
    "\n",
    "def diacritize_sequence(sequence, model, vocab, device):\n",
    "    uppercase_indexes = find_uppercase_indices(sequence)\n",
    "    special_chars_indices = find_special_chars_indices(sequence)\n",
    "\n",
    "    sequence = sequence.lower()\n",
    "\n",
    "    input_seq = prepare_sequence(sequence, vocab, device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seq)\n",
    "        predicted_indices = output.argmax(dim=2).squeeze(0)  \n",
    "\n",
    "    # Decode the predicted sequence of indices back to characters\n",
    "    predicted_sequence = decode_predictions(predicted_indices, vocab)\n",
    "\n",
    "    # Change special characters back to their original form if they were changed\n",
    "    for i, char in special_chars_indices:\n",
    "        predicted_sequence = predicted_sequence[:i] + char + predicted_sequence[i+1:]\n",
    "\n",
    "    predicted_sequence = ''.join([turkish_dict[char] if i in uppercase_indexes and char in turkish_lowercase else char for i, char in enumerate(predicted_sequence)])\n",
    "\n",
    "    return predicted_sequence\n",
    "\n",
    "\n",
    "# Prepare the input sequence\n",
    "\n",
    "sequence1 = \"kendini Roma Imparatoru olarak da tanitan Fatih in Imbrozlu ( gokceada ) tarihcisi Kritovulus soyle yazar: canakkale ye bagli eski Troya kitasinin merkezi olan Ilion sehrine geldiginde kalan yikintilari eski eserleri ve yoreyi seyir ve temasa eyledi denizden ve karadan haiz oldugu onemi takdir etti Ozan Homeros u ovup goklere cikardigi kimseleri ve onlarin yaptigi saygi deger hizmetleri hatirlayip anarak duygularini dile getirdi ve tanri beni bu sehrin ve halkinin muttefiki olarak bu ana kadar koruyup esirgedi\"\n",
    "\n",
    "print(\"Input sequence:    \", sequence1)\n",
    "print(\"Predicted sequence:\", diacritize_sequence(sequence1, model, checkpoint['vocab'], device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
